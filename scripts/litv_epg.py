import os
import sys
import re
import json
import time
import random
import argparse
import requests
import datetime
import pytz
from bs4 import BeautifulSoup
from xml.etree import ElementTree as ET
from xml.dom import minidom

# å…¨å±€æ™‚å€è¨­ç½®
TAIPEI_TZ = pytz.timezone('Asia/Taipei')

# ä»£ç†è¨­ç½® (å¾ç’°å¢ƒè®Šé‡è®€å–)
HTTP_PROXY = os.environ.get('http_proxy', '') or os.environ.get('HTTP_PROXY', '')
HTTPS_PROXY = os.environ.get('https_proxy', '') or os.environ.get('HTTPS_PROXY', '')

PROXIES = {}
if HTTP_PROXY:
    PROXIES['http'] = HTTP_PROXY
if HTTPS_PROXY:
    PROXIES['https'] = HTTPS_PROXY

HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
}

def create_session():
    """å‰µå»ºå¸¶æœ‰ä»£ç†çš„æœƒè©±"""
    session = requests.Session()
    session.headers.update(HEADERS)
    
    if PROXIES:
        print(f"ä½¿ç”¨ä»£ç†: {PROXIES}")
        session.proxies.update(PROXIES)
    else:
        print("æœªè¨­ç½®ä»£ç†ï¼Œä½¿ç”¨ç›´æ¥é€£æ¥")
    
    return session

def parse_channel_list(session):
    """å¾LiTV APIç²å–é »é“æ¸…å–®ï¼ŒåªæŠ“å–ç‰¹å®šIDæ¨¡å¼çš„é »é“"""
    print("é–‹å§‹ç²å–LiTVé »é“æ¸…å–®...")
    
    # LiTVé »é“API
    channel_url = "https://www.litv.tv/_next/data/322e31352e3138/channel.json"
    
    try:
        response = session.get(channel_url, timeout=30)
        response.raise_for_status()
        
        data = response.json()
        print(f"ç²å–çš„é »é“æ•¸æ“šçµæ§‹: {list(data.keys())}")
        
        # å¾ pageProps.introduction.channels ç²å–é »é“åˆ—è¡¨
        channels_data = data.get('pageProps', {}).get('introduction', {}).get('channels', [])
        
        if not channels_data:
            print("âŒ æœªæ‰¾åˆ°é »é“æ•¸æ“š")
            return []
        
        print(f"æ‰¾åˆ° {len(channels_data)} å€‹é »é“")
        
        # å®šç¾©è¦æŠ“å–çš„é »é“IDæ¨¡å¼
        target_patterns = [
            r'^4gtv-4gtv.*',      # 4gtv-4gtvé–‹é ­çš„æ‰€æœ‰é »é“
            r'^litv-ftv.*',       # litv-ftvé–‹é ­çš„æ‰€æœ‰é »é“
            r'^iNEWS$',           # ç²¾ç¢ºåŒ¹é…iNEWS
            r'^litv-longturn.*'   # litv-longturné–‹é ­çš„æ‰€æœ‰é »é“
        ]
        
        channels = []
        for channel in channels_data:
            channel_name = channel.get('title', '').strip()
            channel_id = channel.get('cdn_code', '').strip()
            
            if not channel_name or not channel_id:
                continue
            
            # æª¢æŸ¥é »é“IDæ˜¯å¦ç¬¦åˆç›®æ¨™æ¨¡å¼
            is_target = False
            for pattern in target_patterns:
                if re.match(pattern, channel_id):
                    is_target = True
                    break
            
            if not is_target:
                continue
                
            # è™•ç†logo URL
            logo = channel.get('picture', '')
            if logo and not logo.startswith('http'):
                logo = f"https://fino.svc.litv.tv/{logo.lstrip('/')}"
            
            channels.append({
                "channelName": channel_name,
                "id": channel_id,
                "logo": logo,
                "description": channel.get('description', ''),
                "content_type": channel.get('content_type', 'channel')
            })
        
        print(f"âœ… æˆåŠŸç²å– {len(channels)} å€‹ç›®æ¨™é »é“")
        for channel in channels:
            print(f"   - {channel['channelName']} (ID: {channel['id']})")
        return channels
        
    except Exception as e:
        print(f"âŒ ç²å–é »é“æ¸…å–®å¤±æ•—: {str(e)}")
        import traceback
        traceback.print_exc()
        return []

def parse_date_from_title(date_text):
    """å¾æ—¥æœŸæ¨™é¡Œè§£ææ—¥æœŸ"""
    try:
        # è™•ç† "ä»Šæ—¥ / 11æœˆ1æ—¥ / æ˜ŸæœŸå…­" æ ¼å¼
        parts = date_text.split(' / ')
        if len(parts) >= 2:
            date_part = parts[1]  # "11æœˆ1æ—¥"
            
            # ç²å–ç•¶å‰å¹´ä»½
            current_year = datetime.datetime.now().year
            
            # è§£ææœˆä»½å’Œæ—¥æœŸ
            month_match = re.search(r'(\d+)æœˆ', date_part)
            day_match = re.search(r'(\d+)æ—¥', date_part)
            
            if month_match and day_match:
                month = int(month_match.group(1))
                day = int(day_match.group(1))
                
                # å‰µå»ºæ—¥æœŸå°è±¡
                date_obj = datetime.datetime(current_year, month, day, tzinfo=TAIPEI_TZ)
                return date_obj
    except Exception as e:
        print(f"âš ï¸ æ—¥æœŸè§£æå¤±æ•—: {date_text}, éŒ¯èª¤: {str(e)}")
    
    return None

def fetch_channel_epg(session, channel_id, channel_name):
    """å¾é »é“é é¢ç²å–ç¯€ç›®è¡¨æ•¸æ“š"""
    print(f"\né–‹å§‹ç²å–é »é“ {channel_name} çš„ç¯€ç›®è¡¨...")
    
    # é »é“é é¢URL
    channel_url = f"https://www.litv.tv/channel/watch/{channel_id}"
    
    try:
        response = session.get(channel_url, timeout=30)
        response.raise_for_status()
        
        # è§£æHTML
        soup = BeautifulSoup(response.text, 'html.parser')
        
        # èª¿è©¦ï¼šä¿å­˜HTMLä»¥ä¾¿æª¢æŸ¥
        with open(f"debug_{channel_id}.html", "w", encoding="utf-8") as f:
            f.write(soup.prettify())
        print(f"âœ… å·²ä¿å­˜HTMLåˆ° debug_{channel_id}.html ç”¨æ–¼èª¿è©¦")
        
        programs = []
        current_date = None
        
        # æ–¹æ³•1: æŸ¥æ‰¾åŒ…å«ç¯€ç›®è¡¨çš„å®¹å™¨
        # å˜—è©¦å¤šç¨®å¯èƒ½çš„é¸æ“‡å™¨
        selectors = [
            'div.grow.overflow-y-auto',
            'div[class*="overflow-y-auto"]',
            'div[class*="epg"]',
            'div[class*="schedule"]',
            'div[class*="program"]'
        ]
        
        epg_container = None
        for selector in selectors:
            epg_container = soup.select_one(selector)
            if epg_container:
                print(f"âœ… ä½¿ç”¨é¸æ“‡å™¨æ‰¾åˆ°ç¯€ç›®è¡¨å®¹å™¨: {selector}")
                break
        
        if not epg_container:
            print("âŒ æœªæ‰¾åˆ°ç¯€ç›®è¡¨å®¹å™¨ï¼Œå˜—è©¦å‚™ç”¨æ–¹æ³•...")
            # å‚™ç”¨æ–¹æ³•ï¼šæŸ¥æ‰¾æ‰€æœ‰åŒ…å«æ™‚é–“å’Œç¯€ç›®åç¨±çš„div
            all_divs = soup.find_all('div')
            for div in all_divs:
                text = div.get_text(strip=True)
                if re.match(r'\d{1,2}:\d{2}\s+.+', text):
                    print(f"æ‰¾åˆ°ç¯€ç›®è¡Œ: {text}")
        
        # å¦‚æœæ‰¾åˆ°å®¹å™¨ï¼Œè§£æå…¶ä¸­çš„ç¯€ç›®
        if epg_container:
            # æŸ¥æ‰¾æ‰€æœ‰ç›´æ¥å­å…ƒç´ 
            for child in epg_container.children:
                if child.name == 'div':
                    classes = child.get('class', [])
                    class_str = ' '.join(classes) if classes else ''
                    text = child.get_text(strip=True)
                    
                    print(f"æª¢æŸ¥å…ƒç´ : class='{class_str}', text='{text}'")
                    
                    # æª¢æŸ¥æ˜¯å¦æ˜¯æ—¥æœŸæ¨™é¡Œ
                    if text and ('ä»Šæ—¥' in text or 'æœˆ' in text and 'æ—¥' in text):
                        print(f"ğŸ“… æ‰¾åˆ°æ—¥æœŸæ¨™é¡Œ: {text}")
                        current_date = parse_date_from_title(text)
                        if current_date:
                            print(f"  è§£æç‚º: {current_date.strftime('%Y-%m-%d')}")
                    
                    # æª¢æŸ¥æ˜¯å¦æ˜¯ç¯€ç›®è¡Œ - ä½¿ç”¨æ›´å¯¬é¬†çš„æ¢ä»¶
                    elif text and re.match(r'\d{1,2}:\d{2}\s+.+', text):
                        time_match = re.match(r'(\d{1,2}):(\d{2})\s+(.+)', text)
                        if time_match and current_date:
                            hour = int(time_match.group(1))
                            minute = int(time_match.group(2))
                            program_name = time_match.group(3)
                            
                            # è¨ˆç®—ç¯€ç›®é–‹å§‹æ™‚é–“
                            program_start = current_date.replace(hour=hour, minute=minute, second=0)
                            
                            # é è¨­ç¯€ç›®æ™‚é•·ç‚º1å°æ™‚
                            program_end = program_start + datetime.timedelta(hours=1)
                            
                            programs.append({
                                "channelName": channel_name,
                                "programName": program_name,
                                "description": "",
                                "subtitle": "",
                                "start": program_start,
                                "end": program_end
                            })
                            
                            print(f"   ğŸ“º ç¯€ç›®: {hour:02d}:{minute:02d} - {program_name}")
        
        # æ–¹æ³•2: å¦‚æœä¸Šé¢æ²’æ‰¾åˆ°ï¼Œå˜—è©¦æœç´¢æ•´å€‹æ–‡æª”ä¸­çš„ç¯€ç›®è¡Œ
        if not programs:
            print("å˜—è©¦æ–¹æ³•2: æœç´¢æ•´å€‹æ–‡æª”ä¸­çš„ç¯€ç›®è¡Œ")
            all_elements = soup.find_all(text=re.compile(r'\d{1,2}:\d{2}\s+.+'))
            for element in all_elements:
                text = element.strip()
                time_match = re.match(r'(\d{1,2}):(\d{2})\s+(.+)', text)
                if time_match and current_date:
                    hour = int(time_match.group(1))
                    minute = int(time_match.group(2))
                    program_name = time_match.group(3)
                    
                    program_start = current_date.replace(hour=hour, minute=minute, second=0)
                    program_end = program_start + datetime.timedelta(hours=1)
                    
                    programs.append({
                        "channelName": channel_name,
                        "programName": program_name,
                        "description": "",
                        "subtitle": "",
                        "start": program_start,
                        "end": program_end
                    })
                    
                    print(f"   ğŸ“º ç¯€ç›®: {hour:02d}:{minute:02d} - {program_name}")
        
        print(f"âœ… é »é“ {channel_name} ç²å–åˆ° {len(programs)} å€‹ç¯€ç›®")
        return programs
        
    except Exception as e:
        print(f"âŒ ç²å–é »é“ {channel_name} ç¯€ç›®è¡¨å¤±æ•—: {str(e)}")
        import traceback
        traceback.print_exc()
        return []

def get_litv_epg():
    """ç²å–LiTVé›»è¦–ç¯€ç›®è¡¨"""
    print("="*50)
    print("é–‹å§‹ç²å–LiTVé›»è¦–ç¯€ç›®è¡¨")
    print("="*50)
    
    # å‰µå»ºæœƒè©±
    session = create_session()
    
    # ç²å–é »é“æ¸…å–®
    channels_info = parse_channel_list(session)
    if not channels_info:
        print("âŒ ç„¡æ³•ç²å–é »é“æ¸…å–®")
        return [], [], []  # è¿”å›ä¸‰å€‹ç©ºåˆ—è¡¨
    
    # ç‚ºæ¯å€‹é »é“ç²å–ç¯€ç›®è¡¨
    all_programs = []
    for channel in channels_info:
        channel_id = channel["id"]
        channel_name = channel["channelName"]
        
        # ç²å–è©²é »é“çš„ç¯€ç›®è¡¨
        programs = fetch_channel_epg(session, channel_id, channel_name)
        all_programs.extend(programs)
        
        # æ·»åŠ éš¨æ©Ÿå»¶é²ï¼Œé¿å…è«‹æ±‚éæ–¼é »ç¹
        delay = random.uniform(2, 5)
        print(f"ç­‰å¾… {delay:.1f} ç§’å¾Œç¹¼çºŒ...")
        time.sleep(delay)
    
    # æ ¼å¼åŒ–é »é“è³‡è¨Šï¼ˆç”¨æ–¼XMLTVç”Ÿæˆï¼‰
    all_channels = []
    for channel in channels_info:
        channel_info = {
            "name": channel["channelName"],
            "channelName": channel["channelName"],
            "id": channel["id"],
            "url": f"https://www.litv.tv/channel/{channel['id']}",
            "source": "litv",
            "desc": channel.get("description", ""),
            "sort": "å°ç£"
        }
        
        if channel.get("logo"):
            channel_info["logo"] = channel["logo"]
        
        all_channels.append(channel_info)
    
    # çµ±è¨ˆçµæœ
    print("\n" + "="*50)
    print(f"âœ… æˆåŠŸç²å– {len(all_channels)} å€‹é »é“")
    print(f"âœ… æˆåŠŸç²å– {len(all_programs)} å€‹ç¯€ç›®")
    
    # æŒ‰é »é“åç¨±åˆ†çµ„é¡¯ç¤ºç¯€ç›®æ•¸é‡
    channel_counts = {}
    for program in all_programs:
        channel_counts[program["channelName"]] = channel_counts.get(program["channelName"], 0) + 1
    
    for channel, count in channel_counts.items():
        print(f"ğŸ“º é »é“ {channel}: {count} å€‹ç¯€ç›®")
    
    print("="*50)
    return channels_info, all_channels, all_programs  # è¿”å›ä¸‰å€‹å€¼

def generate_xmltv(channels, programs, output_file="litv.xml"):
    """ç”ŸæˆXMLTVæ ¼å¼çš„EPGæ•¸æ“š"""
    print(f"\nç”ŸæˆXMLTVæª”æ¡ˆ: {output_file}")
    
    if not channels or not programs:
        print("âŒ æ²’æœ‰é »é“æˆ–ç¯€ç›®æ•¸æ“šï¼Œç„¡æ³•ç”ŸæˆXMLTV")
        return False
    
    # å»ºç«‹XMLæ ¹å…ƒç´ 
    root = ET.Element("tv", generator="LITV-EPG-Generator", source="www.litv.tv")
    
    # é »é“1 -> é »é“1ç¯€ç›® -> é »é“2-> é »é“2ç¯€ç›® -> ...
    program_count = 0
    for channel in channels:
        channel_name = channel['name']
        
        # æ·»åŠ é »é“å®šç¾©
        channel_elem = ET.SubElement(root, "channel", id=channel_name)
        ET.SubElement(channel_elem, "display-name", lang="zh").text = channel_name
        
        if channel.get('logo'):
            ET.SubElement(channel_elem, "icon", src=channel['logo'])
        
        # ç²å–è©²é »é“çš„æ‰€æœ‰ç¯€ç›®
        channel_programs = [p for p in programs if p['channelName'] == channel_name]
        if not channel_programs:
            print(f"âš ï¸ é »é“ {channel_name} æ²’æœ‰ç¯€ç›®æ•¸æ“š")
            continue
            
        # æŒ‰é–‹å§‹æ™‚é–“æ’åº
        channel_programs.sort(key=lambda p: p['start'])
        
        # æ·»åŠ è©²é »é“çš„æ‰€æœ‰ç¯€ç›®
        for program in channel_programs:
            try:
                start_time = program['start'].strftime('%Y%m%d%H%M%S %z')
                end_time = program['end'].strftime('%Y%m%d%H%M%S %z')
                
                program_elem = ET.SubElement(
                    root, 
                    "programme", 
                    channel=channel_name,
                    start=start_time, 
                    stop=end_time
                )
                
                title = program.get('programName', 'æœªçŸ¥ç¯€ç›®')
                ET.SubElement(program_elem, "title", lang="zh").text = title
                
                if program.get('subtitle'):
                    ET.SubElement(program_elem, "sub-title", lang="zh").text = program['subtitle']
                
                if program.get('description'):
                    ET.SubElement(program_elem, "desc", lang="zh").text = program['description']
                
                program_count += 1
            except Exception as e:
                print(f"âš ï¸ è·³éç„¡æ•ˆçš„ç¯€ç›®æ•¸æ“š: {str(e)}")
                continue
    
    # ç”ŸæˆXMLå­—ç¬¦ä¸²
    xml_str = ET.tostring(root, encoding='utf-8').decode('utf-8')
    
    # ç¾åŒ–XMLæ ¼å¼
    try:
        parsed = minidom.parseString(xml_str)
        pretty_xml = parsed.toprettyxml(indent="  ", encoding='utf-8')
    except Exception as e:
        print(f"âš ï¸ XMLç¾åŒ–å¤±æ•—, ä½¿ç”¨åŸå§‹XML: {str(e)}")
        pretty_xml = xml_str.encode('utf-8')
    
    # å„²å­˜åˆ°æª”æ¡ˆ
    try:
        with open(output_file, 'wb') as f:
            f.write(pretty_xml)
        
        print(f"âœ… XMLTVæª”æ¡ˆå·²ç”Ÿæˆ: {output_file}")
        print(f"ğŸ“º é »é“æ•¸: {len(channels)}")
        print(f"ğŸ“º ç¯€ç›®æ•¸: {program_count}")
        print(f"ğŸ’¾ æª”æ¡ˆå¤§å°: {os.path.getsize(output_file) / 1024:.2f} KB")
        return True
    except Exception as e:
        print(f"âŒ å„²å­˜XMLæª”æ¡ˆå¤±æ•—: {str(e)}")
        return False

def generate_channel_json(channels_info, output_file="litv.json"):
    """ç”ŸæˆJSONæ ¼å¼çš„é »é“è³‡è¨Š"""
    print(f"\nç”ŸæˆJSONé »é“æª”æ¡ˆ: {output_file}")
    
    if not channels_info:
        print("âŒ æ²’æœ‰é »é“æ•¸æ“šï¼Œç„¡æ³•ç”ŸæˆJSON")
        return False
    
    try:
        # æ ¼å¼åŒ–é »é“è³‡è¨Šç‚ºæ‰€éœ€çš„JSONæ ¼å¼
        json_channels = []
        for channel in channels_info:
            json_channel = {
                "channelName": channel["channelName"],
                "id": channel["id"],
                "logo": channel.get("logo", ""),
                "description": channel.get("description", "")
            }
            json_channels.append(json_channel)
        
        # å¯«å…¥JSONæª”æ¡ˆ
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(json_channels, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… JSONé »é“æª”æ¡ˆå·²ç”Ÿæˆ: {output_file}")
        print(f"ğŸ“º é »é“æ•¸: {len(json_channels)}")
        print(f"ğŸ’¾ æª”æ¡ˆå¤§å°: {os.path.getsize(output_file) / 1024:.2f} KB")
        return True
        
    except Exception as e:
        print(f"âŒ ç”ŸæˆJSONé »é“æª”æ¡ˆå¤±æ•—: {str(e)}")
        return False

def main():
    """ä¸»å‡½æ•¸ï¼Œè™•ç†å‘½ä»¤è¡Œåƒæ•¸"""
    parser = argparse.ArgumentParser(description='LiTVé›»è¦–ç¯€ç›®è¡¨')
    parser.add_argument('--output', type=str, default='output/litv.xml', 
                       help='è¼¸å‡ºXMLæª”æ¡ˆè·¯å¾‘ (é»˜èª: output/litv.xml)')
    parser.add_argument('--json', type=str, default='output/litv.json',
                       help='è¼¸å‡ºJSONé »é“æª”æ¡ˆè·¯å¾‘ (é»˜èª: output/litv.json)')
    parser.add_argument('--debug', action='store_true',
                       help='å•Ÿç”¨èª¿è©¦æ¨¡å¼ï¼Œä¿å­˜HTMLæ–‡ä»¶')
    
    args = parser.parse_args()
    
    # ç¢ºä¿è¼¸å‡ºç›®éŒ„å­˜åœ¨
    output_dir = os.path.dirname(args.output)
    if output_dir and not os.path.exists(output_dir):
        os.makedirs(output_dir, exist_ok=True)
        print(f"å»ºç«‹è¼¸å‡ºç›®éŒ„: {output_dir}")
    
    json_dir = os.path.dirname(args.json)
    if json_dir and not os.path.exists(json_dir):
        os.makedirs(json_dir, exist_ok=True)
        print(f"å»ºç«‹JSONè¼¸å‡ºç›®éŒ„: {json_dir}")
    
    try:
        # ç²å–EPGæ•¸æ“š
        channels_info, all_channels, programs = get_litv_epg()
        
        if not channels_info:
            print("âŒ æœªç²å–åˆ°é »é“æ•¸æ“šï¼Œç„¡æ³•ç”ŸæˆXMLå’ŒJSON")
            sys.exit(1)
            
        # ç”ŸæˆXMLTVæª”æ¡ˆ
        if not generate_xmltv(all_channels, programs, args.output):
            print("âš ï¸ XMLTVæª”æ¡ˆç”Ÿæˆå¤±æ•—ï¼Œä½†ç¹¼çºŒç”ŸæˆJSONæª”æ¡ˆ")
            
        # ç”ŸæˆJSONé »é“æª”æ¡ˆ
        if not generate_channel_json(channels_info, args.json):
            print("âŒ JSONé »é“æª”æ¡ˆç”Ÿæˆå¤±æ•—")
            sys.exit(1)
            
        print(f"\nğŸ‰ æ‰€æœ‰æª”æ¡ˆç”Ÿæˆå®Œæˆï¼")
        print(f"ğŸ“„ XMLTV EPGæª”æ¡ˆ: {args.output}")
        print(f"ğŸ“„ JSONé »é“æª”æ¡ˆ: {args.json}")
            
    except Exception as e:
        print(f"âŒ ä¸»ç¨‹åºéŒ¯èª¤: {str(e)}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

if __name__ == "__main__":
    main()
